from tensorflow.keras import preprocessing
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Rescaling, Conv2D, Dense, Flatten, MaxPooling2D, Dropout, GlobalAveragePooling2D
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
import numpy as np
print("---------------------------CNN with pooling layer-----------------------------")
##training_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="training", label_mode="categorical", seed=0, image_size=(100,100))
test_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="validation", label_mode="categorical",  seed=0, image_size=(100,100))
##m = Sequential()
##m.add(Rescaling(1/255))
##m.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(100,100,3)))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Flatten())
##m.add(Dense(128, activation='relu'))
##m.add(Dropout(0.5))
##m.add(Dense(5, activation='softmax'))
##m.compile(loss="categorical_crossentropy", metrics=['accuracy'])
##history  = m.fit(training_set, batch_size=32, epochs=25,verbose=0)
##m.save("my_model.h5")
old_model = load_model("my_model.h5")
##print(old_model["accuracy"])
#print(training_set.class_names)
#print("Testing.")
score = old_model.evaluate(test_set, verbose=0)
print('Test accuracy:', score[1])
print(old_model.summary())
##image_file = "flowers/sunflower/10386525695_2c38fea555_n.jpg"
##img = preprocessing.image.load_img(image_file,target_size=(100,100))
##img_arr = preprocessing.image.img_to_array(img)
##plt.imshow(img_arr.astype("uint8"))
##plt.show()
##img_cl = img_arr.reshape(1,100,100,3)
##score = old_model.predict(img_cl)
##print(score)
    
    
print("\n")                                                              
print("---------------------------CNN without dropout layer-----------------------------")    
##training_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="training", label_mode="categorical", seed=0, image_size=(100,100))
test_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="validation", label_mode="categorical",  seed=0, image_size=(100,100))
##m = Sequential()
##m.add(Rescaling(1/255))
##m.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(100,100,3)))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Flatten())
##m.add(Dense(128, activation='relu'))
##m.add(Dense(5, activation='softmax'))
##m.compile(loss="categorical_crossentropy", metrics=['accuracy'])
##history  = m.fit(training_set, batch_size=32, epochs=25,verbose=0)
##m.save("my_model_wout_drop.h5")
old_model2 = load_model("my_model_wout_drop.h5")
##print(history.history["accuracy"])
##print(training_set.class_names)
##print("Testing.")
score = old_model2.evaluate(test_set, verbose=0)
print('Test accuracy:', score[1])
print(old_model2.summary())
highest = score[1]
##image_file = "flowers/sunflower/10386525695_2c38fea555_n.jpg"
##img = preprocessing.image.load_img(image_file,target_size=(100,100))
##img_arr = preprocessing.image.img_to_array(img)
##plt.imshow(img_arr.astype("uint8"))
##plt.show()
##img_cl = img_arr.reshape(1,100,100,3)
##score = old_model2.predict(img_cl)
##print(score)
print("\n")
print("---------------------------CNN with different image size and no dropout-----------------------------")
##training_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="training", label_mode="categorical", seed=0, image_size=(125,125))
test_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="validation", label_mode="categorical",  seed=0, image_size=(125,125))
##m = Sequential()
##m.add(Rescaling(1/255))
##m.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(125,125,3)))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Flatten())
##m.add(Dense(128, activation='relu'))
##m.add(Dense(5, activation='softmax'))
##m.compile(loss="categorical_crossentropy", metrics=['accuracy'])
##history  = m.fit(training_set, batch_size=32, epochs=25,verbose=0)
##m.save("my_model_img_size.h5")
old_model3 = load_model("my_model_img_size.h5")
##print(history.history["accuracy"])
##print(training_set.class_names)
##print("Testing.")
score = old_model3.evaluate(test_set, verbose=0)
print('Test accuracy:', score[1])
print(old_model3.summary())
##image_file = "flowers/sunflower/10386525695_2c38fea555_n.jpg"
##img = preprocessing.image.load_img(image_file,target_size=(125,125))
##img_arr = preprocessing.image.img_to_array(img)
##plt.imshow(img_arr.astype("uint8"))
##plt.show()
##img_cl = img_arr.reshape(1,125,125,3)
##score = old_model3.predict(img_cl)
##print(score)


print("\n")
print("---------------------------CNN with different filters and no dropout-----------------------------")
##training_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="training", label_mode="categorical", seed=0, image_size=(100,100))
test_set = preprocessing.image_dataset_from_directory("flowers", validation_split=0.2, subset="validation", label_mode="categorical",  seed=0, image_size=(100,100))
##m = Sequential()
##m.add(Rescaling(1/255))
##m.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=(100,100,3)))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(128, kernel_size=(5, 5), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))
##m.add(MaxPooling2D(pool_size=(2, 2)))
##m.add(Flatten())
##m.add(Dense(128, activation='relu'))
##m.add(Dense(5, activation='softmax'))
##m.compile(loss="categorical_crossentropy", metrics=['accuracy'])
##history  = m.fit(training_set, batch_size=32, epochs=25,verbose=0)
##m.save("my_model_filter.h5")
old_model4 = load_model("my_model_filter.h5")
##print(history.history["accuracy"])
##print(training_set.class_names)
##print("Testing.")
score = old_model4.evaluate(test_set, verbose=0)                                                                                                                                                                                                        
print('Test accuracy:', score[1])
print(old_model4.summary())
##image_file = "flowers/rose/12202373204_34fb07205b.jpg"
##img = preprocessing.image.load_img(image_file,target_size=(100,100))
##img_arr = preprocessing.image.img_to_array(img)
##plt.imshow(img_arr.astype("uint8"))
##plt.show()
##img_cl = img_arr.reshape(1,100,100,3)
##score = old_model4.predict(img_cl)
##print(score)

print("\n")
print("The CNN model with no dropout layer has the highest test accuracy of: ", highest)
print("\n")
print("---------------------------CNN classifying 10 images-----------------------------")
print("\n")
print("Classifying 10 images of different flowers with the best CNN model")
print("\n")
old_model2 = load_model("my_model_wout_drop.h5")
image_file = ['10images/daisy1.jpg', '10images/daisy2.jpg', '10images/dandelion1.jpg', '10images/dandelion2.jpg', '10images/rose1.jpg', '10images/rose2.jpg', '10images/rose3.jpg', '10images/sunflower1.jpg', '10images/tulip1.jpg', '10images/tulip2.jpg']
for i in image_file:
    img = preprocessing.image.load_img(i,target_size=(100,100))
    img_arr = preprocessing.image.img_to_array(img)
    plt.imshow(img_arr.astype("uint8"))
    plt.show()
    img_cl = img_arr.reshape(1,100,100,3)
    score = old_model2.predict(img_cl)
    print(score)
    print(np.amax(score))

